---
title: "Getting and Cleaning Data - Final Assignment"
author: "Olmedo Alonso Madrigales"
date: "09/24/2020"
output: html_document
---

## Description

The purpose of this project is to demonstrate my ability to collect, work with, and clean data. The goal that has been established in the course is to prepare tidy data that can be used for later analysis. 

## Assignment

I am submitting: 1) a tidy data set contained in the file *tidy_merged_data_avg.txt*, 2) a link to a Github repository with the script for performing the analysis, and 3) a code book that describes the variables, the data, and any transformations or work that were performed to clean up the data called CodeBook.md. This repo explains how all of the scripts work and how they are connected.

## Dataset

The data was provided in the following link as a zipfile. I had to get it, cleaned it and manipulate it in order to obtaining the solution for the requirements of the assignment.

(http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)

## The Script

The script I created was *run_analisys.R*. It is also posted in the GitHub repo. Here I describe it as follows:

### I. Preparation steps

A. Load the following packages that I find important to have available in case are needed.
  
  - library(dplyr)
  - library(tidyr)
  - library(httr)
  - library(RCurl)
  - library(data.table)
  - library(knitr)

B. Setting the working directory
  
    > setwd("C:/Users/Olmedo/Desktop/Coursera/datasciencecoursera")

C. Pre Assignment Activities
  
  - Getting and cleaning the Data

  1. Download the file and put it in the folder
    
    > if(!file.exists("./Get&CleanDataAssignment")){dir.create(./Get&CleanDataAssignment")}
    > fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
    > download.file(fileUrl, destfile="./Get&CleanDataAssignment/DataAssignment.zip")

  2. Unzip the file to the folder
    
    > unzip(zipfile = "./Get&CleanDataAssignment/DataAssignment.zip", exdir = "./Get&CleanDataAssignment")

  3. Unzip the files that are in the folder.  I created a function "pathway" for the path.
    
    > pathway <- file.path("./Get&CleanDataAssignment", "UCI HAR Dataset")

  4. Read the data sets into the variables. I created them similarly to the files names provided in the zipfile in order to have an easy track.

    > x_test <- read.table(file.path(pathway, "test", "X_test.txt"), header = FALSE)
    > x_train <- read.table(file.path(pathway, "train", "X_train.txt"), header = FALSE)
    > y_test <- read.table(file.path(pathway, "test", "y_test.txt"), header = FALSE)
    > y_train <- read.table(file.path(pathway, "train", "y_train.txt"), header = FALSE)
    > sub_test <- read.table(file.path(pathway, "test", "subject_test.txt"), header = FALSE)
    > sub_train <- read.table(file.path(pathway, "train", "subject_train.txt"),header = FALSE)
    > features <- read.table(file.path(pathway, "features.txt"), header = FALSE)
    > activities <- read.table(file.path(pathway, "activity_labels.txt"), header = FALSE)

  5. Merge the test, train sets and subject to create only one data set x variable. ThatÂ´s in order to get the data tidier in the way to answer the assignment      requirements.
    
    > x_data <- rbind(x_test, x_train)
    > names(x_data) <- features$V2
    > y_data <- rbind(y_test, y_train)
    > names(y_data) <- c("activity")
    > sub_data <- rbind(sub_test, sub_train)
    > names(sub_data) <- c("subject")
    > merged_data <- cbind(sub_data, y_data, x_data)

### II. Assignment Development

  1. Extract only the measurements of the mean and std dev for each measurement in order to have the data tidier.
    
    > tidy_merged _data <- merged_data %>% select(subject, activity, contains("mean"), contains("std"))

  2. Use descriptive activity names to name the activities in the data set. With this I have the specific measurement for each subject activity.
    
    > tidy_merged_data$activity <- activities[tidy_merged_data$activity, 2]

  3. Appropriately labels the data set with descriptive variable names. Here I place adjust the title for each column (variable) to be easier to understand.
    
    > names(tidy_merged_data) [1] = "Subject"
    > names(tidy_merged_data) [2] = "Activity"
    > names(tidy_merged_data) <- gsub("^t", "Time", names(tidy_merged_data))
    > names(tidy_merged_data) <- gsub("^f", "Frequency", names(tidy_merged_data))
    > names(tidy_merged_data) <- gsub("Acc", "Accelerometer", names(tidy_merged_data))
    > names(tidy_merged_data) <- gsub("Gyro", "Gyroscope", names(tidy_merged_data))
    > names(tidy_merged_data) <- gsub("Mag", "Magnitud", names(tidy_merged_data))
    > names(tidy_merged_data) <- gsub("BodyBody", "Body", names(tidy_merged_data))
    > names(tidy_merged_data) <- gsub("-mean", "Mean", names(tidy_merged_data))
    > names(tidy_merged_data) <- gsub("-std", "STD", names(tidy_merged_data))
    > names(tidy_merged_data) <- gsub("-freq", "Frecuency", names(tidy_merged_data))
    > names(tidy_merged_data) <- gsub("angle", "Angle", names(tidy_merged_data))
    > names(tidy_merged_data) <- gsub("gravity", "Gravity", names(tidy_merged_data))
   
   4. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject. With this       table I provide a summirized data by each subject and activity.
  
    > tidy_merged_data_avg <- tidy_merged_data %>% group_by(Subject, Activity) %>% summarise_all(list(mean = mean))

   5. Save the new table. This allows me to keep the table locally and ready for sharing it to others.
    
    > write.table(tidy_merged_data_avg, "./Get&CleanDataAssignment/tidy_merged_data_avg.txt", row.names = FALSE)

I also provided a CodeBook.Rmd in the GitHub repo for this assignment.


